{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7cXfz0cao0H"
   },
   "source": [
    "# Assignment 6\n",
    "\n",
    "Name 1: Sangeet Sagar<br/>\n",
    "Student id 1: 7009050<br/>\n",
    "Email 1: sasa00001@stud.uni-saarland.de<br/>\n",
    "\n",
    "\n",
    "Name 2: Nikhil Paliwal<br/>\n",
    "Student id 2: 7009915<br/>\n",
    "Email 2: nipa00002@stud.uni-saarland.de<br/> \n",
    "\n",
    "**Instructions:** Read each question carefully. <br/>\n",
    "Make sure you appropriately comment your code wherever required. Your final submission should contain the completed Notebook and the Python file for exercise 3. There is no need to submit the data files. <br/>\n",
    "Upload the zipped folder in Teams. Make sure to click on \"Turn-in\" after your upload your submission, otherwise the assignment will not be considered as submitted. Only one from the group should make the submisssion.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yi9e8HHYbq7T"
   },
   "source": [
    "## Exercise 1: MLE & MAP  (3 points)\n",
    "\n",
    "Here is a nice [article](http://pages.cs.wisc.edu/~jerryzhu/cs838/LM.pdf) that explains the difference between MLE and MAP based estimation for language models. \n",
    "\n",
    "**1.1 (1 point)**\n",
    "\n",
    "* Is a MAP estimator always better than MLE? Why is MAP preferred over MLE (explain in context of language modelling)? (0.5 points)\n",
    "\n",
    "* Some smoothing methods use a MAP estimation of the model parameters. One of these is floor discounting, as described on Slide 44 in Chapter 5. <br/>\n",
    "Write the formula for deriving the MAP estimate and the resultant formula for floor discounting. What underlying distribution does the language model assume? What is assumed as the prior? (0.5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer** <br>\n",
    "- MAP is preferred over MLE in cases where words in the vocabulary are missing in the training corpus. MAP takes care of zero probablity by assigning some probability mass from the higher counts to the zero counts. Thus MAP is capable to give probablity to any kind of text irrespective of its presence in the corpus.\n",
    "\n",
    "- Formula for deriving the MAP estimate\n",
    "$$\n",
    "P(w|h) = \\frac{1}{z}(N(w, h) + \\epsilon)\n",
    "$$\n",
    "\n",
    "Formula for floor discounting\n",
    "$$\n",
    "P(w|h) = \\frac{N(w, h) + \\epsilon}{N(h) + \\epsilon \\cdot V}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $N(w, h): $ Frequency of the combination  $h, w$\n",
    "- $N(h): $ Frequency of $h$\n",
    "- $\\epsilon: $ discounting parameter, typically $ 0 < \\epsilon \\leq 1$\n",
    "\n",
    "It assumes multinomial distribution with Dirichlet priors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yi9e8HHYbq7T"
   },
   "source": [
    "**1.2 (2 points)**\n",
    "\n",
    "Consider the sentences\n",
    "\n",
    "`s1 = They don't know that we know they know!`\n",
    "\n",
    "`s2 = Don't we know that?`\n",
    "\n",
    "* Assume punctuation removal and lowercasing as basic preprocessing steps. Formulate a bigram model (use a circular corpus) on `s1`, note down the conditional probabilities, and use them to determine the probability of `s2`. (0.5 pt)\n",
    "* Now use floor discounting and form similar bigram models with $\\epsilon=1$ and $\\epsilon=0.5$, note down the respective bigram probabilities, and use them to determine the probability of `s2`. (1 pt) \n",
    "* What do you observe? How does the value of $\\epsilon$ influence the MAP prior in both cases? (0.5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer** <br>\n",
    "1. \n",
    "s1 = `they dont know that we know they know` <br>\n",
    "bigrams = ('they', 'dont'), ('dont', 'know'), ('know', 'that'), ('that', 'we'), ('we', 'know'), ('know', 'they'), ('they', 'know'), ('know', 'they') <br>\n",
    "\n",
    "```\n",
    "P(dont| they) = 0.500\n",
    "P(know| dont) = 1.000\n",
    "P(that| know) = 0.333\n",
    "P(we| that) = 1.000\n",
    "P(know| we) = 1.000\n",
    "P(they| know) = 0.667\n",
    "P(know| they) = 0.500\n",
    "P(they| know) = 0.667\n",
    "\n",
    "\n",
    "P(we| dont) = 0.000\n",
    "P(know| we) = 1.000\n",
    "P(that| know) = 0.333\n",
    "P(dont| that) = 0.000\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "2. \n",
    "$\\epsilon = 0.5$\n",
    "\n",
    "```\n",
    "P(dont| they) = 0.333\n",
    "P(know| dont) = 0.429\n",
    "P(that| know) = 0.273\n",
    "P(we| that) = 0.429\n",
    "P(know| we) = 0.429\n",
    "P(they| know) = 0.455\n",
    "P(know| they) = 0.333\n",
    "P(they| know) = 0.455\n",
    "\n",
    "\n",
    "P(we| dont) = 0.143\n",
    "P(know| we) = 0.429\n",
    "P(that| know) = 0.273\n",
    "P(dont| that) = 0.143\n",
    "```\n",
    "\n",
    "$\\epsilon = 1$\n",
    "\n",
    "```\n",
    "P(dont| they) = 0.286\n",
    "P(know| dont) = 0.333\n",
    "P(that| know) = 0.250\n",
    "P(we| that) = 0.333\n",
    "P(know| we) = 0.333\n",
    "P(they| know) = 0.375\n",
    "P(know| they) = 0.286\n",
    "P(they| know) = 0.375\n",
    "\n",
    "\n",
    "P(we| dont) = 0.167\n",
    "P(know| we) = 0.333\n",
    "P(that| know) = 0.250\n",
    "P(dont| that) = 0.167\n",
    "```\n",
    "\n",
    "\n",
    "3.\n",
    "\n",
    "No smoothing | $\\epsilon=0.5$ | $\\epsilon=1$\n",
    "- | - | -\n",
    "![alt](image/1.png) | ![alt](image/2.png) | ![alt](image/3.png)\n",
    "\n",
    "Observe that with $\\epsilon=1$ the probablity distribution becomes more smooth. It means the sharing of probablities to lower counts was performed to higher extent than in the case with $\\epsilon=0.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jjZwN7YbrMM"
   },
   "source": [
    "## Exercise 2: Good-Turing (3 points)\n",
    "\n",
    "#### 2.1: Estimate of unknown words (0.5 points)\n",
    "\n",
    "Imagine that you're given a split into (1) training data and (2) test data. They come from the same distribution but you're forbidden to make any other splits.\n",
    "\n",
    "- What is the MLE estimate of frequency of unseen words on (2)?\n",
    "- What other, better, strategy could be employed to estimate frequency of unseen words from (1) on (2)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer** <br>\n",
    "- MLE estimate of frequency of unseen words are $0$.\n",
    "- Frequency of such unseen words can be repalced with the net frequency of all singleton word types (i.e. total frequency of words whose frequency is 1). This is basically the intution behind Good-Turing Estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jjZwN7YbrMM"
   },
   "source": [
    "#### 2.2: Data split (0.5 points)\n",
    "\n",
    "- Usually when preparing a new model, we split the dataset to (1) training data, (2) held-out data and (3) test data. Comment briefly on what each part of the dataset is used for and especially on the distinction between (1) and (2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer** <br>\n",
    "Held out data is used to set meta-parameters. We use training data to train some ngram model and using this we determine the (best) parameters (lambda) that gives the highest probablity on the held-out dataset. Those parameters are finally used to determine the distribution on the test data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jjZwN7YbrMM"
   },
   "source": [
    "#### 2.3: Good-Turing Formula (1 point)\n",
    "\n",
    "- What is the formula for updated counts for words of frequency $k \\ne 0$?\n",
    "- What is the Good-Turing formula for estimating unseen words, $k=0$?\n",
    "- Given the updated counts $c^*_k$, how does Good-Turing estimate relate to language model smoothing? How do you define the smoothed distribution?\n",
    "- Is there any systematic relationship between the original counts and the new counts? e.g. for large enough $k$, $c^*_k \\ge k$. \n",
    "- Compute and compare the absolute frequencies and Good-Turing estimates for the words `three` and `syringes` in the following text.\n",
    "\n",
    "```\n",
    "thirty - three thousand three hundred and thirty silver syringes which cost three hundred and thirty - two crowns . .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "1. \n",
    "$$\n",
    "c^*_k = (c_k+1)\\frac{N_{k+1}}{N_k}\n",
    "$$\n",
    "\n",
    "2. \n",
    "$$\n",
    "c^*_k = \\frac{N_{1}}{N}\n",
    "$$\n",
    "where: <br>\n",
    "- $N_{k}$: Frequency of frequency of $k$ (i.e. freuency of all such words that occur $k$ times)\n",
    "\n",
    "3. Good turing estimate actually follows the idea - Use the counts of what we have seen once to estimate things we have seen zero times. The smoothed distribution is a power law distribution.\n",
    "\n",
    "4. Yes, for large enough $k$, $$c^*_k = c_k$$.\n",
    "\n",
    "5. We have \n",
    "```\n",
    "'thirty': 3,\n",
    "'three': 3,\n",
    "'hundred': 2,\n",
    "'and': 2,\n",
    "'thousand': 1,\n",
    "'silver': 1,\n",
    "'syringes': 1,\n",
    "'which': 1,\n",
    "'cost': 1,\n",
    "'two': 1,\n",
    "'crowns': 1\n",
    "```\n",
    "$N = 17$ <br>\n",
    "$N_1 = 7$ <br>\n",
    "$N_2 = 2$ <br>\n",
    "$N_3 = 2$ <br>\n",
    "\n",
    "- Seen thrice `three`\n",
    "    - Take k = 3\n",
    "    - MLE_p = $\\frac{3}{17}$\n",
    "    - $C^*({\\text{three}}) = (3+1) \\cdot \\frac{N_4}{N_3} = 4 \\cdot \\frac{2}{2} = 4$ (since $k$ is large here)\n",
    "    - $P^*_{GT}(\\text{three}) = \\frac{4}{17} = 0.235$\n",
    "    - $P^*_{absolute}(\\text{three}) = \\frac{3}{17} = 0.1764$\n",
    "\n",
    "\n",
    "- Seen once `syringes`\n",
    "    - Take k = 1\n",
    "    - MLE_p = $\\frac{1}{17}$\n",
    "    - $C^*({\\text{syringes}}) = 2*\\frac{N_2}{N_1} = 2*\\frac{2}{7} = \\frac{4}{7}$\n",
    "    - $P^*_{GT}(\\text{syringes}) = \\frac{\\frac{4}{7}}{17} = 0.0336$\n",
    "    - $P^*_{absolute}(\\text{syringes}) = \\frac{1}{17} = 0.0588$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jjZwN7YbrMM"
   },
   "source": [
    "#### 2.4: Frequent buckets (1 point)\n",
    "\n",
    "- In your own words, what is the issue with Good-Turing when estimating the new counts for the very frequent words?\n",
    "- See page 5, paragraph 3 of [Good‚ÄêTuring Smoothing Without Tears](http://deanfoster.net/teaching/data_mining/good_turing.pdf) by Gale and Sampson (1995). What solution do they propose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer** <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HztKiKEpbrXt"
   },
   "source": [
    "## Exercise 3: Cross-Validation (4 points)\n",
    "\n",
    "<!-- ### 3.0 Bible studies -->\n",
    "\n",
    "Imagine you are a linguist in the remote future who just rediscovered a book called \"Bible\". To your disappointment the book is obviously incomplete; all the pages between Genesis and the Apocalypse are torn out, maybe by some late Christian cult. Since you don't know the language of the book you want to build a first language model that you can use if you find any of the lost parts. You digitize the book with your state-of-the art portable digitizer, and then load it into one of your Python 10.0 notebooks.\n",
    "\n",
    "**3.1 Baseline (0.5 points)**\n",
    "\n",
    "* The two corpora are in the text files `genesis.txt` and `apocalypsis.txt`. Load them into the notebook, preprocess them by removing all non-alphabetical characters, and then concatenate them into a single corpus. Split the corpus into a train and a test set, with the test set comprising the _last_ 20% of the corpus. You may use your code from previous exercises for this. (0.25 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "id": "rDVzYp5zKSVC"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "from pathlib import Path\n",
    "import re\n",
    "import random\n",
    "import string\n",
    "from importlib import reload\n",
    "import exercise_3\n",
    "exercise_3 = reload(exercise_3)\n",
    "\n",
    "genesis_text = Path(\"data/genesis.txt\").open('r').read()\n",
    "apocalypsis_text = Path(\"data/apocalypsis.txt\").open('r').read()\n",
    "\n",
    "# preprocess\n",
    "def preprocess(text):\n",
    "    file_content = text.lower()\n",
    "    file_content = file_content.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens_list = file_content.split()\n",
    "    return tokens_list\n",
    "\n",
    "# genesis_preprocessed = re.sub('[^A-Za-z]+', ' ', genesis_text)\n",
    "# apocalypsis_preprocessd = re.sub('[^A-Za-z]+', ' ', apocalypsis_text)\n",
    "\n",
    "genesis_preprocessed = preprocess(genesis_text)\n",
    "apocalypsis_preprocessd = preprocess(apocalypsis_text)\n",
    "\n",
    "# concatenate\n",
    "corpus = genesis_preprocessed + apocalypsis_preprocessd\n",
    "\n",
    "# train, test split\n",
    "train, test = exercise_3.train_test_split_data(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uk5YNPJ_Ky0s"
   },
   "source": [
    "* Using your language model class from the previous assignment, estimate a trigram language model on the train set and report perplexity on the test. Use $\\alpha=1$. Does this represent an unbiased estimate of the model's capacity? (0.25 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "id": "0NsFQMfyPcl1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity of trigram LM = 3680.0276784664616\n"
     ]
    }
   ],
   "source": [
    "# TODO: trigram LM\n",
    "import lm\n",
    "lm = reload(lm)\n",
    "\n",
    "N = 3\n",
    "LM = lm.LanguageModel(train, test, N=N, alpha=1)\n",
    "pp = LM.perplexity()\n",
    "\n",
    "\n",
    "print('Perplexity of trigram LM = {}'.format(pp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9uIbyb7LoYT"
   },
   "source": [
    "**3.2 Average Perplexity (2 points)**\n",
    "\n",
    "* Since you want to get an unbiased estimate of your model's capacity, you decide to apply k-fold cross-validation on your corpus. To do this, implement the function `k_validation_folds` in `exercise_2.py`. Use it to split your corpus into $k=5$ cross-validation folds, and make sure that the folds are of the same size. (1 point)\n",
    "\n",
    "* Now, estimate a trigram language model on each of the CV folds. You may again use your class from the previous assignment, and average over all perplexity scores. Does the average score differ from the one obtained in 3.2, and why? (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "id": "5d2o5fTiMo13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average perplexity for 5-folds 2868.120649043175\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "exercise_3 = reload(exercise_3)\n",
    "# 5-fold cross-validation\n",
    "k_folds = 5\n",
    "cv_folds = exercise_3.k_validation_folds(corpus, k_folds)\n",
    "\n",
    "\n",
    "\n",
    "# estimate 5 trigram LMs!\n",
    "pp_folds = np.zeros(k_folds)\n",
    "for i in range(k_folds):\n",
    "    train = cv_folds[i-1:i] + cv_folds[i+1:] if i != 0 else cv_folds[i+1:]\n",
    "    train = [item for sublist in train for item in sublist]\n",
    "    LM = lm.LanguageModel(train, cv_folds[i], N=N, alpha=1)\n",
    "    pp_folds[i] = LM.perplexity()\n",
    "    \n",
    "avrg_PP = np.sum(pp_folds)/k_folds\n",
    "print('Average perplexity for 5-folds {}'.format(avrg_PP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRakHZmFNALS"
   },
   "source": [
    "**3.3 Hyperparameter Tuning (1.5 points)**\n",
    "\n",
    "* As you don't know anything about the language the book is written in, you have to find the best hyperparemter $\\alpha$ for your model by a brute-force search (recall how you did this in the last assignment). Since you know from 3.2 that your data is not balanced, you decide to use only the averaged perplexity score (derived from $k=5$ CV folds) for this. Do so by completing the loop in the code cell below. Then, plot the obtained perplexity scores vs. $\\alpha$. You do so by reusing the respective function from Assignment 5. (1 point)\n",
    "\n",
    "(**Hint:** This could take a while.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "id": "-ada-400O8kO"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hyperparamter tuning, CV\n",
    "alphas = [x*0.01 for x in range(1,101)]\n",
    "N = 3\n",
    "PPs = []\n",
    "for alpha in alphas:\n",
    "    pp_folds = np.zeros(k_folds)\n",
    "    for i in range(k_folds):\n",
    "        train = cv_folds[i-1:i] + cv_folds[i+1:] if i != 0 else cv_folds[i+1:]\n",
    "        train = [item for sublist in train for item in sublist]\n",
    "        LM = lm.LanguageModel(train, cv_folds[i], N=N, alpha=alpha)\n",
    "        pp_folds[i] = LM.perplexity()\n",
    "\n",
    "    avrg_PP = np.sum(pp_folds)/k_folds\n",
    "    PPs.append(avrg_PP)\n",
    "\n",
    "exercise_3.plot_pp_vs_alpha(PPs, alphas)\n",
    "\n",
    "# TODO: plot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IGq72SKNP-tb"
   },
   "source": [
    "* Repeat the tuning process for unigram and bigram language models. Does your estimate of $\\alpha$ differ? Why? (0.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "id": "4as-q5FJP9wL"
   },
   "outputs": [],
   "source": [
    "# hyperparamter tuning, bigram + trigram\n",
    "\n",
    "PP_dict = dict()\n",
    "N = 3\n",
    "for n in range(1,N):\n",
    "    PPs = []\n",
    "    for alpha in alphas:\n",
    "        pp_folds = np.zeros(k_folds)\n",
    "        for i in range(k_folds):\n",
    "            train = cv_folds[i-1:i] + cv_folds[i+1:] if i != 0 else cv_folds[i+1:]\n",
    "            train = [item for sublist in train for item in sublist]\n",
    "            LM = lm.LanguageModel(train, cv_folds[i], N=N, alpha=alpha)\n",
    "            pp_folds[i] = LM.perplexity()\n",
    "\n",
    "        avrg_PP = np.sum(pp_folds)/k_folds\n",
    "        PPs.append(avrg_PP)\n",
    "    PP_dict[n] = PPs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'unigram': [1633.0210346691529]}"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PPs"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
